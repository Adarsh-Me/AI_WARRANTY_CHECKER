{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "851a8010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\prabhat\\anaconda\\lib\\site-packages (1.0.5)\n",
      "Requirement already satisfied: langchain_community in c:\\users\\prabhat\\anaconda\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-text-splitters in c:\\users\\prabhat\\anaconda\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\prabhat\\anaconda\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\prabhat\\anaconda\\lib\\site-packages (5.1.2)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\prabhat\\anaconda\\lib\\site-packages (0.36.0)\n",
      "Collecting py\n",
      "  Using cached py-1.11.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting pdf\n",
      "  Using cached pdf-2020.11.12-py3-none-any.whl.metadata (789 bytes)\n",
      "Requirement already satisfied: streamlit in c:\\users\\prabhat\\anaconda\\lib\\site-packages (1.37.1)\n",
      "Requirement already satisfied: langgraph in c:\\users\\prabhat\\anaconda\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\prabhat\\anaconda\\lib\\site-packages (2.2.2)\n",
      "Collecting langchain-groq\n",
      "  Downloading langchain_groq-1.0.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.4 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langchain) (1.0.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langchain_community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langchain_community) (2.0.34)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langchain_community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langchain_community) (3.10.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langchain_community) (8.2.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langchain_community) (2.12.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langchain_community) (0.4.42)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langchain_community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from sentence-transformers) (4.57.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from sentence-transformers) (2.9.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from huggingface-hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from huggingface-hub) (2024.6.1)\n",
      "Collecting pdftotree (from pdf)\n",
      "  Using cached pdftotree-0.5.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pdfminer (from pdf)\n",
      "  Using cached pdfminer-20191125.tar.gz (4.2 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting bs4 (from pdf)\n",
      "  Using cached bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Collecting silverware (from pdf)\n",
      "  Using cached silverware-2020.11.12-py3-none-any.whl.metadata (771 bytes)\n",
      "Requirement already satisfied: nltk in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from pdf) (3.9.1)\n",
      "Collecting disk (from pdf)\n",
      "  Using cached disk-2021.6.29-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting chronometry (from pdf)\n",
      "  Using cached chronometry-2020.11.12-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from streamlit) (5.0.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from streamlit) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from streamlit) (5.3.3)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from streamlit) (4.25.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from streamlit) (16.1.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from streamlit) (13.7.1)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from streamlit) (0.8.0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: watchdog<5,>=2.1.5 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from streamlit) (4.0.1)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langgraph) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langgraph) (1.0.2)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langgraph) (0.2.9)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from pandas) (2023.3)\n",
      "Collecting groq<1.0.0,>=0.30.0 (from langchain-groq)\n",
      "  Downloading groq-0.33.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.11.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: toolz in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\prabhat\\appdata\\roaming\\python\\python312\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.7)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.3.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (1.33)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.20.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.21.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2025.4.26)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.15.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.0.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from bs4->pdf) (4.12.3)\n",
      "Collecting slytherin (from chronometry->pdf)\n",
      "  Using cached slytherin-2020.11.12-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting colouration (from chronometry->pdf)\n",
      "  Using cached colouration-2020.7.26-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting sklearn (from chronometry->pdf)\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [15 lines of output]\n",
      "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "      rather than 'sklearn' for pip commands.\n",
      "      \n",
      "      Here is how to fix this error in the main use cases:\n",
      "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "      - if the 'sklearn' package is used by one of your dependencies,\n",
      "        it would be great if you take some time to track which package uses\n",
      "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "      - as a last resort, set the environment variable\n",
      "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "      \n",
      "      More information is available at\n",
      "      https://github.com/scikit-learn/sklearn-pypi-package\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain_community langchain-text-splitters faiss-cpu sentence-transformers huggingface-hub py pdf streamlit langgraph pandas langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "383dd0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langgraph.graph import StateGraph , START , END\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from typing import Dict, Any, TypedDict\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa4664f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims = pd.read_csv('/Users/prabhat/OneDrive/Desktop/codingbase/PYTHON_Codebase/AI_WARAANTY_DETECTOR/Data/warranty_claims - Copy.csv')\n",
    "\n",
    "\n",
    "loader = PyPDFLoader('/Users/prabhat/OneDrive/Desktop/codingbase/PYTHON_Codebase/AI_WARAANTY_DETECTOR/Data/AutoDrive_Warranty_Policy_2025.pdf')\n",
    "load= loader.load()\n",
    "policy_text = \" \".join([doc.page_content for doc in load])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcdc73de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-groq\n",
      "  Using cached langchain_groq-1.0.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting groq<1.0.0,>=0.30.0 (from langchain-groq)\n",
      "  Using cached groq-0.33.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langchain-groq) (1.0.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (2.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.15.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-groq) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-groq) (0.4.42)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-groq) (24.1)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-groq) (6.0.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-groq) (8.2.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1.0.0,>=0.30.0->langchain-groq) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-groq) (2.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-groq) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-groq) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-groq) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-groq) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1.0.0,>=0.30.0->langchain-groq) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1.0.0,>=0.30.0->langchain-groq) (2.20.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-groq) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\prabhat\\anaconda\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-groq) (2.2.3)\n",
      "Downloading langchain_groq-1.0.0-py3-none-any.whl (16 kB)\n",
      "Downloading groq-0.33.0-py3-none-any.whl (135 kB)\n",
      "Installing collected packages: groq, langchain-groq\n",
      "Successfully installed groq-0.33.0 langchain-groq-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dd002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm =  init_chat_model (\"openai/gpt-oss-20b\",model_provider='GROQ',api_key = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37cb083b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassState(TypedDict):\n",
    "    claims:Dict[str,Any]\n",
    "    policy_tracker:str\n",
    "    fraud_tracker:str\n",
    "    fraud_score:float\n",
    "    evidence:str\n",
    "    decision:str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e78fb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_check_agent(State: ClassState) -> ClassState:\n",
    "    claim = State[\"claims\"]\n",
    "\n",
    "    # ✅ Safely get Vehicle Type (use default if missing)\n",
    "    vehicle_type = claim.get(\"Vehicle Type\", \"Unknown\")\n",
    "\n",
    "    # ✅ Infer vtype based on value\n",
    "    if vehicle_type.lower() == \"car\":\n",
    "        vtype = \"Four Wheeler\"\n",
    "    elif vehicle_type.lower() in [\"bike\", \"scooter\", \"motorcycle\"]:\n",
    "        vtype = \"Two Wheeler\"\n",
    "    else:\n",
    "        vtype = \"Unknown\"\n",
    "\n",
    "    # Build your prompt\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert insurance policy analyst. Analyze the following warranty claim details against the provided warranty policy document.\n",
    "\n",
    "    Policy manual:\n",
    "    {policy_text}\n",
    "\n",
    "    Warranty claim details:\n",
    "    vtype: {vtype}\n",
    "    claim: {claim}\n",
    "\n",
    "    Based on the above warranty policy document and claim details, determine:\n",
    "    Answer: Policy is Covered or Not Covered. Provide a brief explanation for your decision.\n",
    "    \"\"\"\n",
    "\n",
    "    # Invoke LLM\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    # Store the result\n",
    "    State[\"policy_tracker\"] = response.content.strip()\n",
    "    return State\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9fdc14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fraud_detection_agent(State: ClassState) -> ClassState:\n",
    "    claim = State['claims']\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert fraud detection analyst. Analyze the following warranty claim details for potential fraud indicators.\n",
    "     warranty policy document :\n",
    "        {policy_text}\n",
    "\n",
    "    claim details:\n",
    "    claim:{claim}\n",
    "\n",
    "        Based on the above warranty policy document and claim details, assess the likelihood of fraud. Provide a fraud score between 0 (no fraud) to 1 (definite fraud) along with a brief explanation.\n",
    "\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    try:\n",
    "        score = float(response.content.strip())\n",
    "    except :\n",
    "        score=0.5\n",
    "    State['evidence'] = response.content.strip()\n",
    "    return State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "630fba31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evidence_collector_agent(State: ClassState) -> ClassState:\n",
    "    claim = State['claims']\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert evidence collection analyst. Based on the following warranty claim details and previous analyses, summarize the key evidence supporting or refuting the claim.\n",
    "\n",
    "     warranty policy document :\n",
    "        {policy_text}\n",
    "\n",
    "    claim details:\n",
    "    claim:{claim}\n",
    "\n",
    "    Previous Analyses:\n",
    "    Policy Analysis: {State['policy_tracker']}\n",
    "    Fraud Detector : {State['fraud_tracker']}\n",
    "    Fraud Score: {State['fraud_score']}\n",
    "\n",
    "     Based on the above information, summarize the key evidence supporting or refuting the claim.\n",
    "        Answer:List any red flags, inconsistencies, or supporting details found in the claim.\n",
    "\n",
    "    Provide a concise summary of the key evidence.\n",
    "\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    State['evidence'] = response.content.strip()\n",
    "    return State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e05f0d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_agent(State: ClassState) -> ClassState:\n",
    "    claim = State['claims']\n",
    "    policy_analysis = State['policy_tracker']\n",
    "  \n",
    "    evidence =  State['evidence']\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert claims decision analyst. Based on the following warranty claim details and previous analyses, make a final decision on the claim.\n",
    "\n",
    "     warranty policy document :\n",
    "        {policy_text}\n",
    "\n",
    "    claim details:\n",
    "    claim:{claim}\n",
    "\n",
    "    Previous Analyses:\n",
    "    Policy Analysis: {State['policy_tracker']}\n",
    "    \n",
    "    Fraud Score: {State['fraud_score']}\n",
    "    Evidence Summary: {State['evidence']}\n",
    "\n",
    "     Based on the above information, make a final decision on the claim.\n",
    "        Answer:Approve or Deny the claim. Provide a brief justification for your decision.\n",
    "\n",
    "    \"\"\"\n",
    "    decision_text = \"\"\n",
    "    try :\n",
    "        if \"approve\" in decision_text.lower():\n",
    "            decision_text = \"Approve\"   \n",
    "        elif \"deny\" in decision_text.lower():\n",
    "            decision_text = \"DisApprove\"\n",
    "\n",
    "        elif \"insufficient\" in evidence.lower():\n",
    "            decision_text = \"Escalate for further review\"\n",
    "\n",
    "    except:\n",
    "        decision_text = \"Escalate for further review\"\n",
    "\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    State['decision'] = response.content.strip()\n",
    "    return State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1a699e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(ClassState)\n",
    "\n",
    "graph.add_node(\"PolicyCheck\", policy_check_agent)\n",
    "graph.add_node(\"FraudScoring\", fraud_detection_agent)\n",
    "graph.add_node(\"EvidenceCollector\", evidence_collector_agent)\n",
    "graph.add_node(\"Action\", action_agent)\n",
    "\n",
    "graph.set_entry_point(\"PolicyCheck\")\n",
    "graph.add_edge(\"PolicyCheck\", \"FraudScoring\")\n",
    "graph.add_edge(\"FraudScoring\", \"EvidenceCollector\")\n",
    "graph.add_edge(\"EvidenceCollector\", \"Action\")\n",
    "graph.add_edge(\"Action\", END)\n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d23ee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for idx, row in claims.iterrows():\n",
    "    state = app.invoke({\"claims\": row.to_dict(), \n",
    "                       \"policy_tracker\": \"\",\n",
    "                       \"fraud_tracker\": \"\",\n",
    "                       \"fraud_score\": 0.0,\n",
    "                       \"evidence\": \"\",\n",
    "                       \"decision\": \"\"})\n",
    "    results.append({\n",
    "        \"claim_id\": row[\"claim_id\"],\n",
    "        \"model\": row[\"model\"],\n",
    "        \"decision\": state[\"decision\"],\n",
    "        \"policy_tracker\": state[\"policy_tracker\"],\n",
    "        \"fraud_score\": state.get(\"fraud_score\", 0.0),\n",
    "        \"evidence\": state[\"evidence\"]\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "673698b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['claim_id', 'model', 'purchase_date', 'claim_date', 'days_since_purchase', 'mileage', 'part_replaced', 'part_cost', 'labor_cost', 'total_cost', 'invoice_present', 'image_present', 'previous_claims']\n"
     ]
    }
   ],
   "source": [
    "print(claims.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfc1e714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_id</th>\n",
       "      <th>model</th>\n",
       "      <th>decision</th>\n",
       "      <th>policy_tracker</th>\n",
       "      <th>fraud_score</th>\n",
       "      <th>evidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLM-DEMO-1</td>\n",
       "      <td>Volt-X (Four-Wheeler, EV Sedan)</td>\n",
       "      <td>**Decision:** Deny\\n\\n**Justification:**  \\nTh...</td>\n",
       "      <td>**Answer: Not Covered**\\n\\n**Explanation:**  \\...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>**Key Evidence Summary**\\n\\n| Evidence | Suppo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLM-DEMO-2</td>\n",
       "      <td>Pulse-3 (Two-Wheeler, Sports Bike)</td>\n",
       "      <td>**Decision:** Deny the claim.\\n\\n**Justificati...</td>\n",
       "      <td>**Answer: Not Covered**\\n\\n**Reasoning**\\n\\n1....</td>\n",
       "      <td>0.0</td>\n",
       "      <td>**Key Evidence Summary – Claim CLM-DEMO-2**\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CLM-DEMO-3</td>\n",
       "      <td>Torque-7 (Four-Wheeler, SUV Diesel)</td>\n",
       "      <td>**Answer: Approve**  \\n\\nThe vehicle is within...</td>\n",
       "      <td>**Answer:** Covered  \\n\\n**Explanation:**  \\n-...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>**Key Evidence Summary**\\n\\n| Evidence | Suppo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CLM-DEMO-APPROVED</td>\n",
       "      <td>Volt-X (Four-Wheeler, EV Sedan)</td>\n",
       "      <td>**Decision:** Approve\\n\\n**Justification:**  \\...</td>\n",
       "      <td>**Answer: Policy is Covered**\\n\\n**Explanation...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>**Key Evidence Summary – Claim CLM‑DEMO‑APPROV...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            claim_id                                model  \\\n",
       "0         CLM-DEMO-1      Volt-X (Four-Wheeler, EV Sedan)   \n",
       "1         CLM-DEMO-2   Pulse-3 (Two-Wheeler, Sports Bike)   \n",
       "2         CLM-DEMO-3  Torque-7 (Four-Wheeler, SUV Diesel)   \n",
       "3  CLM-DEMO-APPROVED      Volt-X (Four-Wheeler, EV Sedan)   \n",
       "\n",
       "                                            decision  \\\n",
       "0  **Decision:** Deny\\n\\n**Justification:**  \\nTh...   \n",
       "1  **Decision:** Deny the claim.\\n\\n**Justificati...   \n",
       "2  **Answer: Approve**  \\n\\nThe vehicle is within...   \n",
       "3  **Decision:** Approve\\n\\n**Justification:**  \\...   \n",
       "\n",
       "                                      policy_tracker  fraud_score  \\\n",
       "0  **Answer: Not Covered**\\n\\n**Explanation:**  \\...          0.0   \n",
       "1  **Answer: Not Covered**\\n\\n**Reasoning**\\n\\n1....          0.0   \n",
       "2  **Answer:** Covered  \\n\\n**Explanation:**  \\n-...          0.0   \n",
       "3  **Answer: Policy is Covered**\\n\\n**Explanation...          0.0   \n",
       "\n",
       "                                            evidence  \n",
       "0  **Key Evidence Summary**\\n\\n| Evidence | Suppo...  \n",
       "1  **Key Evidence Summary – Claim CLM-DEMO-2**\\n\\...  \n",
       "2  **Key Evidence Summary**\\n\\n| Evidence | Suppo...  \n",
       "3  **Key Evidence Summary – Claim CLM‑DEMO‑APPROV...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
